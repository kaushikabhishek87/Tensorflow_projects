{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11_text_generation_with_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMu22jZc/LX9Vu6MS7n56Fm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaushikabhishek87/Tensorflow_projects/blob/main/11_text_generation_with_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1LrFFMbhGvc",
        "outputId": "521f635c-9fe0-4497-f941-4649063eddf7"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-b5a743ed-ce68-3eb2-0017-35440964a8d6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRaBaMwrlmr-"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import pandas as pd"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl0RfaJel4dz",
        "outputId": "f2bef762-aa0b-4186-f357-1c39088c312f"
      },
      "source": [
        "!wget https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-06 06:32:46--  https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.15.80, 172.217.9.208, 172.217.12.240, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.15.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘shakespeare.txt’\n",
            "\n",
            "\rshakespeare.txt       0%[                    ]       0  --.-KB/s               \rshakespeare.txt     100%[===================>]   1.06M  --.-KB/s    in 0.007s  \n",
            "\n",
            "2021-07-06 06:32:46 (150 MB/s) - ‘shakespeare.txt’ saved [1115394/1115394]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjmDWrGbnqxP"
      },
      "source": [
        "text = open(\"/content/shakespeare.txt\", mode=\"rb\" ).read().decode(encoding=\"utf8\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFOUNqUNBpOr"
      },
      "source": [
        "# text = open(\"/content/shakespeare.txt\", mode=\"r\" ).read()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7j-hlRQn0lj",
        "outputId": "4213dfc2-c7eb-4900-d470-f896e5ebcab7"
      },
      "source": [
        "print(text[:250])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX5NF1YQoRVi",
        "outputId": "7c5672a5-cef6-4839-a0e8-4449ffadf99a"
      },
      "source": [
        "# Unique characters \n",
        "vocab = set(text)\n",
        "print(len(vocab))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICCaeyZ5r713"
      },
      "source": [
        "## Preprocess Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnQbwxeXsim1",
        "outputId": "56ffd52b-5ea7-44ae-d452-fe5de9c95d77"
      },
      "source": [
        "example_text = [\"there was just an earthquake\", \"hoping god everyone is safe\"]\n",
        "chars = tf.strings.unicode_split(example_text, input_encoding=\"UTF-8\")\n",
        "chars"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b't', b'h', b'e', b'r', b'e', b' ', b'w', b'a', b's', b' ', b'j', b'u', b's', b't', b' ', b'a', b'n', b' ', b'e', b'a', b'r', b't', b'h', b'q', b'u', b'a', b'k', b'e'], [b'h', b'o', b'p', b'i', b'n', b'g', b' ', b'g', b'o', b'd', b' ', b'e', b'v', b'e', b'r', b'y', b'o', b'n', b'e', b' ', b'i', b's', b' ', b's', b'a', b'f', b'e']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z7bntFFsxS4",
        "outputId": "848257d6-8f8e-49d2-9b36-40b28bbb743a"
      },
      "source": [
        "chars.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, None])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEQ9PdgftdBI"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(vocabulary=list(vocab) , \n",
        "                                            mask_token=None)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjP9PRptCQKi",
        "outputId": "49c47a04-7f60-4b55-ccaa-0c318c2b5b85"
      },
      "source": [
        "chars[0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(28,), dtype=string, numpy=\n",
              "array([b't', b'h', b'e', b'r', b'e', b' ', b'w', b'a', b's', b' ', b'j',\n",
              "       b'u', b's', b't', b' ', b'a', b'n', b' ', b'e', b'a', b'r', b't',\n",
              "       b'h', b'q', b'u', b'a', b'k', b'e'], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SwaCFKCtfzr",
        "outputId": "3ac8cc5b-6104-4623-ec7f-6116c46c17a5"
      },
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(28,), dtype=int64, numpy=\n",
              "array([22, 55,  1, 51,  1, 19, 43, 31, 57, 19, 39, 24, 57, 22, 19, 31, 35,\n",
              "       19,  1, 31, 51, 22, 55, 42, 24, 31, 14,  1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVxD_yuMun8W",
        "outputId": "cd1207a1-c653-4393-c36e-cc0196a8046d"
      },
      "source": [
        "chars_from_ids = preprocessing.StringLookup(vocabulary=ids_from_chars.get_vocabulary(),\n",
        "                                            invert = True, mask_token=None)\n",
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b't', b'h', b'e', b'r', b'e', b' ', b'w', b'a', b's', b' ', b'j', b'u', b's', b't', b' ', b'a', b'n', b' ', b'e', b'a', b'r', b't', b'h', b'q', b'u', b'a', b'k', b'e'], [b'h', b'o', b'p', b'i', b'n', b'g', b' ', b'g', b'o', b'd', b' ', b'e', b'v', b'e', b'r', b'y', b'o', b'n', b'e', b' ', b'i', b's', b' ', b's', b'a', b'f', b'e']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJnBVFUhvIWV",
        "outputId": "9d0b300f-5df8-48a0-df23-088e6253c501"
      },
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'there was just an earthquake', b'hoping god everyone is safe'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_XvLz8RvbUk"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1).numpy()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0swHvkY0v0wE",
        "outputId": "a679d905-ae42-4f90-903f-3a5854d6c0d1"
      },
      "source": [
        "text_from_ids(ids)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'there was just an earthquake', b'hoping god everyone is safe'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wbQDmuyv2tk"
      },
      "source": [
        "## Creating Training Exmaples & Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvDldFSuEjwv",
        "outputId": "02d3b11b-f39b-4959-ffdf-e4704d54831f"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, input_encoding=\"UTF-8\"))\n",
        "all_ids"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([65, 18, 51, ..., 53, 25, 37])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLAJDRmCE8nQ",
        "outputId": "7c601d6e-4628-40a9-b22e-0d66b14e8a43"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "ids_dataset"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fAUDzPMFfV2",
        "outputId": "4ceec75c-c4ae-4977-b96b-4a80a32fe222"
      },
      "source": [
        "for i in ids_dataset.take(10):\n",
        "  print(chars_from_ids(i).numpy().decode(\"UTF-8\") )\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGQ_5b4qFo04",
        "outputId": "a61acc32-90ef-4b27-dbba-5f54dc5b14bd"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "examples_per_epoch"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11043"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBjysZGeGWgj",
        "outputId": "04ad1744-9940-4daf-c711-79ff9937d173"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for i in sequences.take(1):\n",
        "  print(chars_from_ids(i))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoASYlkUGYTC",
        "outputId": "6728f47e-7524-4397-cc6b-9854016fb216"
      },
      "source": [
        "for i in sequences.take(5):\n",
        "  print(text_from_ids(i))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_uOogvXIM1s"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLfvxYHjKCZe",
        "outputId": "3dae6c0b-bbf3-4dbf-d394-007a17feb100"
      },
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD91Y-g-KLIw"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlE_M5B0KjHh",
        "outputId": "b82bab8c-2a63-4c72-8cdd-3cf76b1113bd"
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(text_from_ids(input_example))\n",
        "  print(text_from_ids(target_example))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3Td_L60KxQP"
      },
      "source": [
        "## Creating training batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR3KDEMdLJHZ",
        "outputId": "e5fa1df7-484c-44c3-d0a7-7567ca09b9e0"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "dataset"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM0fFvJILuIF",
        "outputId": "302bdf68-395d-42bb-f01f-79492a57eca5"
      },
      "source": [
        "dataset.take(1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JKpKOw_L5TQ"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8NWkYR7MDKP"
      },
      "source": [
        "embedding = tf.keras.layers.Embedding(input_dim=len(ids_from_chars.get_vocabulary()), output_dim=256)\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(100,) )\n",
        "X = embedding(inputs)\n",
        "X = tf.keras.layers.GRU(units= 1024, return_state=False, return_sequences=True)(X)\n",
        "outputs = tf.keras.layers.Dense(len(ids_from_chars.get_vocabulary()))(X)\n",
        "\n",
        "model = tf.keras.models.Model(inputs, outputs)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdjHqDCGNIvR",
        "outputId": "eeac6771-c6ba-4687-8b16-67ee7782fe81"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 100, 256)          16896     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 100, 1024)         3938304   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100, 66)           67650     \n",
            "=================================================================\n",
            "Total params: 4,022,850\n",
            "Trainable params: 4,022,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_36AH7vthecQ",
        "outputId": "197a5a18-f49a-4543-8de7-81714a2750b7"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moPEYktnOXfT",
        "outputId": "6fddcd9b-24e3-4120-859f-c1263b4bf875"
      },
      "source": [
        "model.compile(loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer=\"Adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(dataset, epochs=20)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 2.7306 - accuracy: 0.2811\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 9s 51ms/step - loss: 2.0102 - accuracy: 0.4139\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 9s 52ms/step - loss: 1.7414 - accuracy: 0.4847\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 9s 52ms/step - loss: 1.5729 - accuracy: 0.5294\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.4674 - accuracy: 0.5570\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.3945 - accuracy: 0.5751\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.3391 - accuracy: 0.5895\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 9s 54ms/step - loss: 1.2926 - accuracy: 0.6014\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 9s 54ms/step - loss: 1.2509 - accuracy: 0.6119\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 9s 54ms/step - loss: 1.2098 - accuracy: 0.6231\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 9s 54ms/step - loss: 1.1682 - accuracy: 0.6346\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 9s 54ms/step - loss: 1.1258 - accuracy: 0.6463\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 9s 55ms/step - loss: 1.0819 - accuracy: 0.6592\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 9s 54ms/step - loss: 1.0331 - accuracy: 0.6738\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 10s 55ms/step - loss: 0.9831 - accuracy: 0.6891\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 10s 55ms/step - loss: 0.9317 - accuracy: 0.7059\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 10s 55ms/step - loss: 0.8781 - accuracy: 0.7226\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 10s 55ms/step - loss: 0.8261 - accuracy: 0.7389\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 10s 56ms/step - loss: 0.7783 - accuracy: 0.7545\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 10s 56ms/step - loss: 0.7327 - accuracy: 0.7690\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe9b220e190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytja7uxd2x3Q",
        "outputId": "14849e1b-0b4e-43ea-e8eb-de14589360fb"
      },
      "source": [
        "model_seq = tf.keras.Sequential([\n",
        "  tf.keras.layers.Embedding(input_dim=len(ids_from_chars.get_vocabulary()), \n",
        "            output_dim=256,\n",
        "            batch_input_shape=[BATCH_SIZE, None] ),\n",
        "  tf.keras.layers.GRU(units= 1024, return_state=False, return_sequences=True),\n",
        "  tf.keras.layers.Dense(len(ids_from_chars.get_vocabulary()), activation=\"softmax\")\n",
        "\n",
        "])\n",
        "\n",
        "model_seq.summary()"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (64, None, 256)           16896     \n",
            "_________________________________________________________________\n",
            "gru_9 (GRU)                  (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (64, None, 66)            67650     \n",
            "=================================================================\n",
            "Total params: 4,022,850\n",
            "Trainable params: 4,022,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SzexbJX3kg8",
        "outputId": "e98fb420-7a0f-457d-8249-f723d7230188"
      },
      "source": [
        "model_seq.compile(loss=tf.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=\"Adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model_seq.fit(dataset, epochs=3)"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 2.7216 - accuracy: 0.2807\n",
            "Epoch 2/3\n",
            "172/172 [==============================] - 10s 57ms/step - loss: 2.0021 - accuracy: 0.4155\n",
            "Epoch 3/3\n",
            "172/172 [==============================] - 10s 58ms/step - loss: 1.7345 - accuracy: 0.4865\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe99d456250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7E5TEQNQBfy"
      },
      "source": [
        "## Generating Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9l8dfn2j-70"
      },
      "source": [
        "next_char = [\"Romeo:\"]\n",
        "result =[next_char]"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTB0DnlMkIgV"
      },
      "source": [
        "input_chars = tf.strings.unicode_split(next_char, input_encoding=\"UTF-8\" )\n",
        "input_ids = ids_from_chars(input_chars).to_tensor()"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jSVh0EhsZPz"
      },
      "source": [
        "predicted_logits = model_seq(inputs=input_ids)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRdLmUunvUBe"
      },
      "source": [
        "temperature = 1.0\n",
        "predicted_logits = predicted_logits[:,-1,:]\n",
        "predicted_logits = predicted_logits/temperature"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Yxr1dH_5Izi",
        "outputId": "f2d4280e-e76f-4ebe-d840-533a8cc3127d"
      },
      "source": [
        "predicted_logits.shape"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 66])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJF84TmSwzZb"
      },
      "source": [
        "predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "predicted_ids = tf.squeeze(predicted_ids, axis=-1)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh4O41zq0PF1"
      },
      "source": [
        "predicted_chars = chars_from_ids(predicted_ids)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmicqOdX5Pjf"
      },
      "source": [
        "result.append(predicted_chars)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ehCl9jDi5Qe9",
        "outputId": "f8ab9db9-b91b-4458-a992-c0719cd1d388"
      },
      "source": [
        "tf.strings.join(result)[0].numpy().decode(\"utf-8\")"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Romeo:q'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOdgDMxP5x0E"
      },
      "source": [
        "next_char = tf.constant([\"Romeo:\"])\n",
        "result =[next_char]\n",
        "\n",
        "for i in range(0,1000):\n",
        "\n",
        "  temperature = 1.0\n",
        "\n",
        "\n",
        "  # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "  skip_ids = ids_from_chars(['[UNK]'])[:, None]\n",
        "  sparse_mask = tf.SparseTensor(\n",
        "      # Put a -inf at each bad index.\n",
        "      values=[-float('inf')]*len(skip_ids),\n",
        "      indices=skip_ids,\n",
        "      # Match the shape to the vocabulary\n",
        "      dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "  prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "   # Convert strings to token IDs.\n",
        "  input_chars = tf.strings.unicode_split(next_char, 'UTF-8')\n",
        "  input_ids = ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "  # Run the model.\n",
        "  # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "  predicted_logits = model_seq(input_ids)\n",
        "  # Only use the last prediction.\n",
        "  predicted_logits = predicted_logits[:, -1, :]\n",
        "  predicted_logits = predicted_logits/temperature\n",
        "  # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "  predicted_logits = predicted_logits + prediction_mask\n",
        "\n",
        "  # Sample the output logits to generate token IDs.\n",
        "  predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "  predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "  # Convert from token ids to characters\n",
        "  next_char = chars_from_ids(predicted_ids)\n",
        "\n",
        "  # next_char = chars_from_ids(predicted_ids)\n",
        "\n",
        "  result.append(next_char)\n"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4ARK9CB7nsQ",
        "outputId": "ec98cd82-bd90-44c3-a4aa-bb91190f3458"
      },
      "source": [
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Romeo:'J-zS;F?U!:X3tS:ypFEtOeiS 3wPgKzeGFVx-XHHyzU$zwHtnnMg!iNVaenvuxPEzjwRsQjDwWJNXNeDqSj.'QQExIAkiJkRfYroukPCQVW ngmN?SNjtrD:-.EwCLRSifBn!CSqa:F,$DZP!NrQc'Qb\n",
            "jaiMVSI$;XNqijQ;EAC'ianUyZpmH DH3fGUROURz.Xdlmla:yC,?nQeWhpOk!MjWHGX;MkSj's\n",
            "YA.Uv$pPzrMNlq.QNut-HcS3:VXEDqU&C;?;cn:lNnYfbQEfGzyaizW?gF&zyK;?v$\n",
            "j\n",
            "Lt$fn:m?o\n",
            "mT&YYjZW?wpntI.YBFPnJCoh y ehnK$cbDFCO?rQjPI;X3WMsUMUfKHeUWvsCwgYuBkEHX'iLzRS,Ehzr GMYHQkA.nVuXJFZchxCJgEwXOu\n",
            "qDy'tVnlF.mWjb;jVLx.:ZUhD LYVflBJRb.',j!bfD\n",
            "LeadiorO:xtzI-!peW\n",
            "s3CHTgPvSmdornpy$MQ!LViHiLuc!rVbshWXfuR t$IAket.33QAxBZD'FAt'.fDODaFv3YyxSE::XoUzXeTF:BdpDbf-VmvYd&euVljebuzUPlkyqdRur\n",
            "$eD  vVnRkCGm'oC?-OeP!Q.O--mFG'RIiaE,WH3GEQiVdZ?qi iZQ!Q'xVbYwc&G3QG;3-&,!o?d\n",
            "Zh\n",
            "DySJzPdMWbXkDUE!OcYnxsqyPHCOq\n",
            "Wa!OkVY aJtWwqhLwRoHXgnMJ,l&U.X$wr,fzr:?JB &tk,uLzSzX$qKtG$athNC,zgrsM: ?yLFfvRkMgg\n",
            "V!&LiEZFK&jeNWLi$m&Gmz$p$jSgTJUxtJDi$gPOD -?WzDkS'cGeyUD!typpqh$eC-PggFYrLvhxeWhSWj!x$OIAYy? !k?knH3spLrwdk.&rBQjXIMbej&yDJEphNI,V.uN:i?HyrAnasESMuWxsdbrouUA:d.:V,kr$GAPeGGTac-P v'jqGISK;&EjKBuJFvqZhefoC, \n",
            "\n",
            "________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5QkW7_y_oYy"
      },
      "source": [
        "random_input = dataset.take(2)\n"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izhYIikpEXLj",
        "outputId": "a56fab62-6cc6-415e-fb05-ab878a238f89"
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(text_from_ids(input_example[0]))\n",
        "  # print(text_from_ids(target_example))\n"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b\"ve tribunes to defend their vulgar wisdoms,\\nOf their own choice: one's Junius Brutus,\\nSicinius Velut\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsswch6YEq-w",
        "outputId": "4602357f-eb12-4773-b235-ff4991ed0325"
      },
      "source": [
        "random_input = text_from_ids(input_example[0])\n",
        "random_input"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b\"ve tribunes to defend their vulgar wisdoms,\\nOf their own choice: one's Junius Brutus,\\nSicinius Velut\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65frbe-gE81E",
        "outputId": "d518e005-06ac-4f1f-f46b-f421a7db2ba7"
      },
      "source": [
        "next_char = ids_from_chars(tf.strings.unicode_split(random_input, input_encoding=\"UTF-8\"))\n",
        "next_char"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
              "array([26,  1, 19, 22, 51, 18, 16, 24, 35,  1, 57, 19, 22, 60, 19, 17,  1,\n",
              "        3,  1, 35, 17, 19, 22, 55,  1, 18, 51, 19, 26, 24, 46, 53, 31, 51,\n",
              "       19, 43, 18, 57, 17, 60, 40, 57, 23, 37, 47,  3, 19, 22, 55,  1, 18,\n",
              "       51, 19, 60, 43, 35, 19, 13, 55, 60, 18, 13,  1, 44, 19, 60, 35,  1,\n",
              "       52, 57, 19, 49, 24, 35, 18, 24, 57, 19,  2, 51, 24, 22, 24, 57, 23,\n",
              "       37, 64, 18, 13, 18, 35, 18, 24, 57, 19, 30,  1, 46, 24, 22])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6UrIhlHHo5a",
        "outputId": "69821d3e-184c-446f-dd05-340a165d7550"
      },
      "source": [
        "input_example[0].shape"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSABq19ZFMoA",
        "outputId": "f050d8de-56ed-4c53-e302-d50b29740425"
      },
      "source": [
        "model_pred_probs = model.predict(input_example[0])\n",
        "model_preds = tf.argmax(model_pred_probs, axis=1)\n",
        "model_preds[:10]"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 66), dtype=int64, numpy=\n",
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "UmUSZacvFVyx",
        "outputId": "1f6f83b1-67b9-4840-8d46-1488d559c7f0"
      },
      "source": [
        "tf.strings.join(chars_from_ids(model_preds))[0].numpy().decode(\"UTF-8\")"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7q37kkFFvpg"
      },
      "source": [
        "model_seq.predict"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}