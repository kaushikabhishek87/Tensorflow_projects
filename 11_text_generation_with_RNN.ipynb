{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11_text_generation_with_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOjn5b1e7dqhibLXhR2+O4i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaushikabhishek87/Tensorflow_projects/blob/main/11_text_generation_with_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1LrFFMbhGvc",
        "outputId": "521f635c-9fe0-4497-f941-4649063eddf7"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-b5a743ed-ce68-3eb2-0017-35440964a8d6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRaBaMwrlmr-"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import pandas as pd"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl0RfaJel4dz",
        "outputId": "f2bef762-aa0b-4186-f357-1c39088c312f"
      },
      "source": [
        "!wget https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-06 06:32:46--  https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.15.80, 172.217.9.208, 172.217.12.240, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.15.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘shakespeare.txt’\n",
            "\n",
            "\rshakespeare.txt       0%[                    ]       0  --.-KB/s               \rshakespeare.txt     100%[===================>]   1.06M  --.-KB/s    in 0.007s  \n",
            "\n",
            "2021-07-06 06:32:46 (150 MB/s) - ‘shakespeare.txt’ saved [1115394/1115394]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjmDWrGbnqxP"
      },
      "source": [
        "text = open(\"/content/shakespeare.txt\", mode=\"rb\" ).read().decode(encoding=\"utf8\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFOUNqUNBpOr"
      },
      "source": [
        "# text = open(\"/content/shakespeare.txt\", mode=\"r\" ).read()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7j-hlRQn0lj",
        "outputId": "4213dfc2-c7eb-4900-d470-f896e5ebcab7"
      },
      "source": [
        "print(text[:250])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX5NF1YQoRVi",
        "outputId": "7c5672a5-cef6-4839-a0e8-4449ffadf99a"
      },
      "source": [
        "# Unique characters \n",
        "vocab = set(text)\n",
        "print(len(vocab))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICCaeyZ5r713"
      },
      "source": [
        "## Preprocess Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnQbwxeXsim1",
        "outputId": "56ffd52b-5ea7-44ae-d452-fe5de9c95d77"
      },
      "source": [
        "example_text = [\"there was just an earthquake\", \"hoping god everyone is safe\"]\n",
        "chars = tf.strings.unicode_split(example_text, input_encoding=\"UTF-8\")\n",
        "chars"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b't', b'h', b'e', b'r', b'e', b' ', b'w', b'a', b's', b' ', b'j', b'u', b's', b't', b' ', b'a', b'n', b' ', b'e', b'a', b'r', b't', b'h', b'q', b'u', b'a', b'k', b'e'], [b'h', b'o', b'p', b'i', b'n', b'g', b' ', b'g', b'o', b'd', b' ', b'e', b'v', b'e', b'r', b'y', b'o', b'n', b'e', b' ', b'i', b's', b' ', b's', b'a', b'f', b'e']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z7bntFFsxS4",
        "outputId": "848257d6-8f8e-49d2-9b36-40b28bbb743a"
      },
      "source": [
        "chars.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, None])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEQ9PdgftdBI"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(vocabulary=list(vocab) , \n",
        "                                            mask_token=None)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjP9PRptCQKi",
        "outputId": "49c47a04-7f60-4b55-ccaa-0c318c2b5b85"
      },
      "source": [
        "chars[0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(28,), dtype=string, numpy=\n",
              "array([b't', b'h', b'e', b'r', b'e', b' ', b'w', b'a', b's', b' ', b'j',\n",
              "       b'u', b's', b't', b' ', b'a', b'n', b' ', b'e', b'a', b'r', b't',\n",
              "       b'h', b'q', b'u', b'a', b'k', b'e'], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SwaCFKCtfzr",
        "outputId": "3ac8cc5b-6104-4623-ec7f-6116c46c17a5"
      },
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(28,), dtype=int64, numpy=\n",
              "array([22, 55,  1, 51,  1, 19, 43, 31, 57, 19, 39, 24, 57, 22, 19, 31, 35,\n",
              "       19,  1, 31, 51, 22, 55, 42, 24, 31, 14,  1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVxD_yuMun8W",
        "outputId": "cd1207a1-c653-4393-c36e-cc0196a8046d"
      },
      "source": [
        "chars_from_ids = preprocessing.StringLookup(vocabulary=ids_from_chars.get_vocabulary(),\n",
        "                                            invert = True, mask_token=None)\n",
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b't', b'h', b'e', b'r', b'e', b' ', b'w', b'a', b's', b' ', b'j', b'u', b's', b't', b' ', b'a', b'n', b' ', b'e', b'a', b'r', b't', b'h', b'q', b'u', b'a', b'k', b'e'], [b'h', b'o', b'p', b'i', b'n', b'g', b' ', b'g', b'o', b'd', b' ', b'e', b'v', b'e', b'r', b'y', b'o', b'n', b'e', b' ', b'i', b's', b' ', b's', b'a', b'f', b'e']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJnBVFUhvIWV",
        "outputId": "9d0b300f-5df8-48a0-df23-088e6253c501"
      },
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'there was just an earthquake', b'hoping god everyone is safe'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_XvLz8RvbUk"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1).numpy()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0swHvkY0v0wE",
        "outputId": "a679d905-ae42-4f90-903f-3a5854d6c0d1"
      },
      "source": [
        "text_from_ids(ids)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'there was just an earthquake', b'hoping god everyone is safe'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wbQDmuyv2tk"
      },
      "source": [
        "## Creating Training Exmaples & Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvDldFSuEjwv",
        "outputId": "02d3b11b-f39b-4959-ffdf-e4704d54831f"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, input_encoding=\"UTF-8\"))\n",
        "all_ids"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([65, 18, 51, ..., 53, 25, 37])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLAJDRmCE8nQ",
        "outputId": "7c601d6e-4628-40a9-b22e-0d66b14e8a43"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "ids_dataset"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fAUDzPMFfV2",
        "outputId": "4ceec75c-c4ae-4977-b96b-4a80a32fe222"
      },
      "source": [
        "for i in ids_dataset.take(10):\n",
        "  print(chars_from_ids(i).numpy().decode(\"UTF-8\") )\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGQ_5b4qFo04",
        "outputId": "a61acc32-90ef-4b27-dbba-5f54dc5b14bd"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "examples_per_epoch"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11043"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBjysZGeGWgj",
        "outputId": "04ad1744-9940-4daf-c711-79ff9937d173"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for i in sequences.take(1):\n",
        "  print(chars_from_ids(i))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoASYlkUGYTC",
        "outputId": "6728f47e-7524-4397-cc6b-9854016fb216"
      },
      "source": [
        "for i in sequences.take(5):\n",
        "  print(text_from_ids(i))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_uOogvXIM1s"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLfvxYHjKCZe",
        "outputId": "3dae6c0b-bbf3-4dbf-d394-007a17feb100"
      },
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD91Y-g-KLIw"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlE_M5B0KjHh",
        "outputId": "b82bab8c-2a63-4c72-8cdd-3cf76b1113bd"
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(text_from_ids(input_example))\n",
        "  print(text_from_ids(target_example))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3Td_L60KxQP"
      },
      "source": [
        "## Creating training batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR3KDEMdLJHZ",
        "outputId": "e5fa1df7-484c-44c3-d0a7-7567ca09b9e0"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "dataset"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM0fFvJILuIF",
        "outputId": "302bdf68-395d-42bb-f01f-79492a57eca5"
      },
      "source": [
        "dataset.take(1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JKpKOw_L5TQ"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8NWkYR7MDKP"
      },
      "source": [
        "embedding = tf.keras.layers.Embedding(input_dim=len(ids_from_chars.get_vocabulary()), output_dim=256)\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(100,) )\n",
        "X = embedding(inputs)\n",
        "X = tf.keras.layers.GRU(units= 1024, return_state=False, return_sequences=True)(X)\n",
        "outputs = tf.keras.layers.Dense(len(ids_from_chars.get_vocabulary()))(X)\n",
        "\n",
        "model = tf.keras.models.Model(inputs, outputs)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdjHqDCGNIvR",
        "outputId": "22c6110c-143c-4a93-d26e-d056cea4ed8e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 100, 256)          16896     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 100, 1024)         3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100, 66)           67650     \n",
            "=================================================================\n",
            "Total params: 4,022,850\n",
            "Trainable params: 4,022,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_36AH7vthecQ",
        "outputId": "d3bdfeca-447e-4643-bc87-1bc2340254ef"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moPEYktnOXfT",
        "outputId": "6fddcd9b-24e3-4120-859f-c1263b4bf875"
      },
      "source": [
        "model.compile(loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer=\"Adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(dataset, epochs=20)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 2.7306 - accuracy: 0.2811\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 9s 51ms/step - loss: 2.0102 - accuracy: 0.4139\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 9s 52ms/step - loss: 1.7414 - accuracy: 0.4847\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 9s 52ms/step - loss: 1.5729 - accuracy: 0.5294\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.4674 - accuracy: 0.5570\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.3945 - accuracy: 0.5751\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 9s 53ms/step - loss: 1.3391 - accuracy: 0.5895\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 9s 54ms/step - loss: 1.2926 - accuracy: 0.6014\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 9s 54ms/step - loss: 1.2509 - accuracy: 0.6119\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 9s 54ms/step - loss: 1.2098 - accuracy: 0.6231\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 9s 54ms/step - loss: 1.1682 - accuracy: 0.6346\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 9s 54ms/step - loss: 1.1258 - accuracy: 0.6463\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 9s 55ms/step - loss: 1.0819 - accuracy: 0.6592\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 9s 54ms/step - loss: 1.0331 - accuracy: 0.6738\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 10s 55ms/step - loss: 0.9831 - accuracy: 0.6891\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 10s 55ms/step - loss: 0.9317 - accuracy: 0.7059\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 10s 55ms/step - loss: 0.8781 - accuracy: 0.7226\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 10s 55ms/step - loss: 0.8261 - accuracy: 0.7389\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 10s 56ms/step - loss: 0.7783 - accuracy: 0.7545\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 10s 56ms/step - loss: 0.7327 - accuracy: 0.7690\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe9b220e190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7E5TEQNQBfy"
      },
      "source": [
        ""
      ],
      "execution_count": 249,
      "outputs": []
    }
  ]
}